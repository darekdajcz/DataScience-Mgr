driver.get(r"https://www.mediaexpert.pl/komputery-i-tablety/laptopy-i-ultrabooki/laptopy?page=1")


from selenium.webdriver.common.by import By
import time
time.sleep(3)

# Akceptujemy wszystkie ciasteczka
try:
    accept_cookies_button = driver.find_element(By.ID, "onetrust-accept-btn-handler")
    accept_cookies_button.click()
    print("Kliknięto przycisk akceptacji ciasteczek")
except:
    print("Przycisk akceptacji ciasteczek nie został znaleziony")



elements = driver.find_elements(By.XPATH, "//div[contains(@class, 'box')]/h2/a[contains(@class, 'is-animate ui-link')]")

# Iterujemy po znalezionych elementach i wypisujemy ich teksty
for element in elements:
    print("Pobrany tekst:", element.text)


# /html/body/main/div[2]/div[2]/div[2]/div[2]/div/div[2]/div[2]/div/div/div/div/div/div[2]/div[3]/div/div/div[3]


from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
import time
import pandas as pd

# Konfiguracja WebDrivera
ds = Service()
driver = webdriver.Chrome(service=ds)

# Lista do przechowywania danych o produktach
products_data = []

# Przechodzimy przez wszystkie strony
# range(1,60)
for page in range(1, 2):  # Możesz zmienić zakres stron
    url = f"https://www.mediaexpert.pl/komputery-i-tablety/laptopy-i-ultrabooki/laptopy?page={page}"
    driver.get(url)
    
    # Czekamy chwilę, aby strona się załadowała
    time.sleep(3)
    
    # Akceptujemy ciasteczka, jeśli przycisk jest obecny
    try:
        accept_cookies_button = driver.find_element(By.ID, "onetrust-accept-btn-handler")
        accept_cookies_button.click()
        print("Kliknięto przycisk akceptacji ciasteczek")
    except:
        print("Przycisk akceptacji ciasteczek nie został znaleziony")

    # Pobieramy elementy dla każdego produktu
    products = driver.find_elements(By.XPATH, "//span/div[contains(@class, 'offer-box')]")
    
    for product in products:
        try:
            # Pobieramy tytuł produktu
            title = product.find_element(By.XPATH, ".//h2/a[contains(@class, 'is-animate ui-link')]").text
        except:
            title = "Brak danych"
        
        try:
            # Pobieramy cenę produktu
            price = product.find_element(By.XPATH, ".//div[contains(@class, 'main-price')]").text
        except:
            price = "Brak ceny"
        
        # Pobieramy szczegóły techniczne z tabeli
        try:
            # Szukamy tabeli w produkcie
            table = product.find_element(By.XPATH, ".//table[contains(@class, 'list attributes')]")
            rows = table.find_elements(By.XPATH, "./tbody/tr")
            
            # Zbieramy dane z tabeli do słownika
            details = {}
            for row in rows:
                try:
                    column_name = row.find_element(By.XPATH, "./th/span").text.strip()
                    value = row.find_element(By.XPATH, "./td/span").text.strip()
                    details[column_name] = value
                except Exception as e:
                    print(f"Błąd w przetwarzaniu szczegółów: {e}")
        except:
            details = {}
        
        # Tworzymy pełny słownik z wszystkimi szczegółami
        product_data = {
            "Tytuł": title,
            "Cena": price,
            "Sklep": "ediaexpert"
        }
        product_data.update(details)  # Dodajemy szczegóły jako osobne kolumny
        
        # Dodajemy produkt do listy
        products_data.append(product_data)

    print(f"--- Zakończono stronę {page} ---")


# Zapisujemy dane do CSV
import pandas as pd

df = pd.DataFrame(products_data)
df.to_csv("produkty_mediaexpert_szczegoly.csv", index=False)
print("Dane zapisano do pliku produkty_mediaexpert_szczegoly.csv")




from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
import time
import pandas as pd

# Konfiguracja WebDrivera
ds = Service()
driver = webdriver.Chrome(service=ds)

# Lista do przechowywania danych o produktach
products_data_media_markt = []

# Przechodzimy przez wszystkie strony
# range(1,17)
for page in range(1, 2):  # Możesz zmienić zakres stron
    url = f"https://mediamarkt.pl/pl/category/laptopy-25867.html?page={page}"
    driver.get(url)
    
    # Czekamy chwilę, aby strona się załadowała
    time.sleep(3)
    
    # Akceptujemy ciasteczka, jeśli przycisk jest obecny
    try:
        accept_cookies_button = driver.find_element(By.ID, "pwa-consent-layer-accept-all-button")
        accept_cookies_button.click()
        print("Kliknięto przycisk akceptacji ciasteczek")
    except Exception as e:
        print("Przycisk akceptacji ciasteczek nie został znaleziony lub wystąpił błąd:", e)


    # Pobieramy elementy dla każdego produktu
    products = driver.find_elements(By.XPATH, "//div/div[contains(@class, 'sc-597dbd60-0 InVqu')]")
    
for product in products:
    try:
        # Pobieramy tytuł produktu w odniesieniu do elementu `product`
        title = product.find_element(By.XPATH, ".//p[contains(@class, 'sc-8b815c14-0 dbwSez')]").text
        print("Tytuł produktu:", title)
    except Exception as e:
        print("Nie udało się pobrać tytułu dla produktu:", e)

print(f"--- Zakończono stronę {page} ---")


# Zapisujemy dane do CSV
import pandas as pd

df = pd.DataFrame(products_data_media_markt)
df.to_csv("produkty_mediamarkt_szczegoly.csv", index=False)
print("Dane zapisano do pliku produkty_mediaexpert_szczegoly.csv")



products = driver.find_elements(By.XPATH, "//div/div[contains(@class, 'sc-597dbd60-0 InVqu')]")

for product in products:
    try:
        # Pobieramy wartość z atrybutu `title` w elemencie <div> o odpowiedniej klasie
        title = product.find_element(By.XPATH, ".//div[contains(@class, 'sc-bc13ac82-0') and @title]").get_attribute("title")
        print("Tytuł produktu:", title)
    except Exception as e:
        print("Nie udało się pobrać tytułu dla produktu:", e)
    try:
        # Znajdujemy kontener z danymi
        table = product.find_element(By.XPATH, ".//dl[contains(@class, 'sc-c838db2c-0 VUoRZ')]")
        rows = table.find_elements(By.XPATH, "./dt")  # Znajdujemy wszystkie `dt`
        
        values = table.find_elements(By.XPATH, "./dt")  # Znajdujemy wszystkie `dt`
    
        # Inicjalizujemy słownik na szczegóły
        details = {}

        for i, dt in enumerate(rows):
            try:
                # Pobieramy nazwę kolumny z `dt`
                column_name = dt.find_element(By.XPATH, ".//p[contains(@class, 'sc-8b815c14-0 kDPqet')]").text.strip()

                # Pobieramy odpowiadającą wartość z `dd` - ten sam indeks co `dt`
                dd = table.find_elements(By.XPATH, "./dd")[i]
                column_value = dd.find_element(By.XPATH, "./div/p").text.strip()

                print('xxxxx')
                print(column_name)
                print(column_value)
                print('xxxxx')

                # Dodajemy kolumnę i wartość do słownika
                details[column_name] = column_value
            except Exception as e:
                print(f"Błąd przy przetwarzaniu pary dt-dd: {e}")

        # Wyświetlamy dane szczegółowe dla produktu
        print("Szczegóły produktu:", details)
    except Exception as e:
        print("Nie udało się pobrać szczegółów dla produktu:", e)

    product_data = {
            "Tytuł": title,
            "Sklep": "MediaMarkt"
         }    
    product_data.update(details)  # Dodajemy szczegóły jako osobne kolumny

    products_data_media_markt.append(product_data)

df = pd.DataFrame(products_data_media_markt)
df.to_csv("produkty_mediamarkt_szczegoly.csv", index=False)
print("Dane zapisano do pliku produkty_mediaexpert_szczegoly.csv")




